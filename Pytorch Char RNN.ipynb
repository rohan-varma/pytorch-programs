{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115393\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = open('./data/shakespeare.txt').read()\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, *, input_size, embedding_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # map inputs to embeddings\n",
    "        self.embedding_layer = nn.Embedding(input_size, embedding_size)\n",
    "        # forward embeddings through LSTM\n",
    "        self.LSTM = nn.LSTM(embedding_size, hidden_size, n_layers)\n",
    "        # compute a linear transformation to output space\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.embedding_layer(input.view(1, -1))\n",
    "        output, hidden = self.LSTM(input.view(1, 1, -1), hidden)\n",
    "        output = self.linear(output.view(1, -1))\n",
    "        scores = F.softmax(output)\n",
    "        return output, hidden, scores\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(self.n_layers, 1, self.hidden_size)),\n",
    "                autograd.Variable(torch.zeros(self.n_layers, 1, self.hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "\n",
    "def get_seq(seq_len = 200):\n",
    "    start = np.random.randint(0, file_len - seq_len)\n",
    "    seq = file[start:start + seq_len]\n",
    "    assert len(seq) == 200\n",
    "    return seq\n",
    "\n",
    "def to_vector(seq, chars = all_characters):\n",
    "    return autograd.Variable(torch.LongTensor([chars.index(s) for s in seq]))\n",
    "\n",
    "def generate_training_set():\n",
    "    seq = get_seq()\n",
    "    inputs, labels = to_vector(seq[:-1]), to_vector(seq[1:])\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.init_hidden()\n",
    "    prime_input = to_vector(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        print('doing this shit')\n",
    "        _, hidden, scores = rnn(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden, scores = rnn(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        \n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = to_vector(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "A\n",
      ")JQV ^;reH}CwGS6}'*\tT*:@\"DEd\f",
      "Z\f",
      "G|Kh){&0c^|h}8.s.;H<y~;8syYxd!r|.K/\n",
      "Wf}qy_(\\ikMSvPFpxrS\n",
      "9l^T0OqsX@_(\n",
      "LOSS: 4.6016323852539065\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "hidden_size = 200\n",
    "embedding_size = 100\n",
    "n_layers = 4\n",
    "\n",
    "def my_evaluate(start_char, hidden, predict_len = 100):\n",
    "    predicted_chars = []\n",
    "    for i in range(predict_len):\n",
    "        output, hidden, scores = rnn(start_char, hidden)\n",
    "        idx = np.argmax(scores.data.numpy())\n",
    "        predicted_char = all_characters[idx]\n",
    "        predicted_chars.append(predicted_char)\n",
    "        start_char = to_vector(predicted_char)\n",
    "    assert len(predicted_chars) == 100\n",
    "    return \"\".join([str(x) for x in predicted_chars])\n",
    "        \n",
    "rnn = RNN(input_size = n_characters,\n",
    "          embedding_size = embedding_size,\n",
    "          hidden_size = hidden_size, \n",
    "          output_size = n_characters,\n",
    "          n_layers = n_layers)\n",
    "\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr = 0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "all_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # re-init hidden and zero the grads\n",
    "    hidden = rnn.init_hidden()\n",
    "    rnn.zero_grad()\n",
    "    inputs, labels = generate_training_set()\n",
    "    # run through the inputs one by one, accumulating a loss\n",
    "    loss = 0\n",
    "    for c in range(seq_len - 1):\n",
    "        output, hidden, scores = rnn(inputs[c], hidden)\n",
    "        loss += criterion(output, labels[c])\n",
    "    loss.backward(retain_graph = True)\n",
    "    optim.step()\n",
    "    all_losses.append(loss.data[0]/seq_len)\n",
    "    if epoch % 50 == 0:\n",
    "        print('EPOCH: {}'.format(epoch))\n",
    "        predicted = evaluate()\n",
    "        print(predicted)\n",
    "        print('LOSS: {}'.format(loss.data[0]/seq_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
