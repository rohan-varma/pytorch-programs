{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from __future__ import print_function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(5,3) # constructs a 5 x 3 uniitialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3) # constructs a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4182  0.6396  0.4831\n",
       " 0.4648  0.6661  0.3831\n",
       " 0.9408  0.7842  0.5712\n",
       " 0.0263  0.6101  0.3888\n",
       " 0.1752  0.3362  0.7317\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3217  1.1955  1.2314  0.9688  0.8607  1.6063  1.6687  1.2337  0.9612  1.7032\n",
       " 1.0527  0.8275  1.5964  1.2035  1.0143  0.4124  1.2357  0.5060  1.1581  1.1966\n",
       " 0.7015  0.5993  1.0453  0.4874  0.9319  0.6444  0.1088  0.3469  1.3743  0.5764\n",
       " 1.3172  1.3150  1.0858  1.4504  0.9369  0.5720  1.1942  0.8770  0.7349  0.6698\n",
       " 1.0465  0.7575  0.8843  0.7107  1.2474  0.2038  0.7000  0.7588  0.6227  1.3046\n",
       " 1.3350  0.8743  1.2258  0.0725  0.4950  0.3105  1.6691  1.1792  1.7159  1.5488\n",
       " 0.9818  1.5818  0.8859  1.0409  1.7228  1.4316  0.5474  0.7674  1.6414  0.9048\n",
       " 1.2963  0.9353  0.8523  0.7771  1.3926  0.8089  1.1995  1.2732  1.3307  1.1248\n",
       " 0.4442  1.3130  1.0620  1.0216  0.4081  1.6909  1.5442  0.5568  1.0084  1.0727\n",
       " 1.0791  0.3495  1.3593  0.5951  1.3149  1.1742  1.3435  1.7015  1.0996  1.6919\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = torch.rand(10, 10), torch.rand(10, 10)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3217  1.1955  1.2314  0.9688  0.8607  1.6063  1.6687  1.2337  0.9612  1.7032\n",
       " 1.0527  0.8275  1.5964  1.2035  1.0143  0.4124  1.2357  0.5060  1.1581  1.1966\n",
       " 0.7015  0.5993  1.0453  0.4874  0.9319  0.6444  0.1088  0.3469  1.3743  0.5764\n",
       " 1.3172  1.3150  1.0858  1.4504  0.9369  0.5720  1.1942  0.8770  0.7349  0.6698\n",
       " 1.0465  0.7575  0.8843  0.7107  1.2474  0.2038  0.7000  0.7588  0.6227  1.3046\n",
       " 1.3350  0.8743  1.2258  0.0725  0.4950  0.3105  1.6691  1.1792  1.7159  1.5488\n",
       " 0.9818  1.5818  0.8859  1.0409  1.7228  1.4316  0.5474  0.7674  1.6414  0.9048\n",
       " 1.2963  0.9353  0.8523  0.7771  1.3926  0.8089  1.1995  1.2732  1.3307  1.1248\n",
       " 0.4442  1.3130  1.0620  1.0216  0.4081  1.6909  1.5442  0.5568  1.0084  1.0727\n",
       " 1.0791  0.3495  1.3593  0.5951  1.3149  1.1742  1.3435  1.7015  1.0996  1.6919\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.Tensor(10, 10)\n",
    "torch.add(x, y, out=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3217  1.1955  1.2314  0.9688  0.8607  1.6063  1.6687  1.2337  0.9612  1.7032\n",
       " 1.0527  0.8275  1.5964  1.2035  1.0143  0.4124  1.2357  0.5060  1.1581  1.1966\n",
       " 0.7015  0.5993  1.0453  0.4874  0.9319  0.6444  0.1088  0.3469  1.3743  0.5764\n",
       " 1.3172  1.3150  1.0858  1.4504  0.9369  0.5720  1.1942  0.8770  0.7349  0.6698\n",
       " 1.0465  0.7575  0.8843  0.7107  1.2474  0.2038  0.7000  0.7588  0.6227  1.3046\n",
       " 1.3350  0.8743  1.2258  0.0725  0.4950  0.3105  1.6691  1.1792  1.7159  1.5488\n",
       " 0.9818  1.5818  0.8859  1.0409  1.7228  1.4316  0.5474  0.7674  1.6414  0.9048\n",
       " 1.2963  0.9353  0.8523  0.7771  1.3926  0.8089  1.1995  1.2732  1.3307  1.1248\n",
       " 0.4442  1.3130  1.0620  1.0216  0.4081  1.6909  1.5442  0.5568  1.0084  1.0727\n",
       " 1.0791  0.3495  1.3593  0.5951  1.3149  1.1742  1.3435  1.7015  1.0996  1.6919\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autograd is a tensor-based automatic differentiation library. Autograd requires data of types Variable and Function to build up a computation graph. You can use ```.backward()``` to compute derivatives for backprop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27  27\n",
       " 27  27\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 3*(y**2) # a basic function\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/__init__.py:93: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    }
   ],
   "source": [
    "out.backward(retain_variables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.5000  4.5000\n",
       " 4.5000  4.5000\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Neural Nets in Pytorch\n",
    "- Use ```torch.nn``` package. \n",
    "- NN depends on autograd to differentiate nn loss functions\n",
    "- nn.Module contais layers, and the method forward returns outputs. \n",
    "- Neural Network roadmap:\n",
    "    - Define net that has some learnable weights\n",
    "    - propogate input through the network\n",
    "    - compute the loss function\n",
    "    - compute partial derivatives with respect to the weights and use the backpropagation algorithm to update the weights\n",
    "    - weight update: weight = weighted - (learning rate $*$ gradient + momentum_cost $*$ prev_grad). \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120)\n",
       "  (fc2): Linear(in_features=120, out_features=84)\n",
       "  (fc3): Linear(in_features=84, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x106f35d58>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0546 -0.1738  0.0171  0.1902 -0.0517\n",
       "   0.1902 -0.0532 -0.1967 -0.0101  0.0939\n",
       "  -0.1014  0.0888  0.0987  0.1674  0.0987\n",
       "  -0.0375  0.0479  0.0106 -0.0430  0.0486\n",
       "  -0.0876  0.0446  0.1501 -0.1480  0.1991\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -0.0192  0.1092 -0.1625  0.0245  0.0810\n",
       "  -0.0461 -0.1366 -0.1793 -0.0824  0.0087\n",
       "   0.1822  0.0776 -0.0629  0.1958  0.0443\n",
       "  -0.1477  0.0562 -0.0781  0.1526 -0.0988\n",
       "   0.1778  0.1572  0.0561  0.1521 -0.0874\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.1381  0.1707  0.0515 -0.0099 -0.1072\n",
       "   0.1631  0.1355  0.0371  0.0874 -0.1071\n",
       "  -0.0611 -0.0064 -0.0513 -0.0554 -0.1933\n",
       "   0.0645  0.1497 -0.0412  0.1253 -0.0288\n",
       "   0.0098 -0.1112  0.1924  0.1041  0.0813\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "  -0.0318  0.1625  0.1289 -0.0844 -0.1232\n",
       "   0.1451 -0.0838  0.0380  0.1754  0.0872\n",
       "  -0.0790  0.1047 -0.1569 -0.0257  0.0543\n",
       "   0.1333  0.0690  0.1368 -0.1472  0.1646\n",
       "   0.1891 -0.1897  0.1361 -0.0883  0.0209\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "  -0.0420  0.0543  0.1606  0.1331 -0.0562\n",
       "   0.1034 -0.1384 -0.1328  0.1412  0.0238\n",
       "  -0.0629 -0.0635 -0.1518 -0.0051  0.0183\n",
       "   0.0464  0.0317 -0.0389 -0.1163  0.0675\n",
       "  -0.0463 -0.0740  0.0081  0.0127 -0.0584\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.0668  0.0453  0.1748  0.1024 -0.0946\n",
       "   0.0326  0.1854  0.0911 -0.0126 -0.0345\n",
       "   0.0246  0.0768 -0.0003 -0.0253 -0.0753\n",
       "  -0.0991  0.0392 -0.0620 -0.1306 -0.0972\n",
       "   0.1569  0.0652  0.1008 -0.1757  0.0598\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       " -0.1342\n",
       "  0.1822\n",
       "  0.0264\n",
       " -0.0826\n",
       "  0.0967\n",
       "  0.0634\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.2859  7.7399 -7.9100 -5.3442 -3.4909\n",
       "   0.5505  5.6740 -7.3003 -2.3861  7.2795\n",
       "   0.4814  6.2212 -7.5291  2.7934 -2.2350\n",
       "  -4.2540 -5.3318 -1.2541 -1.5103 -4.8818\n",
       "   1.5025 -4.2700 -1.7193 -0.5950 -7.4100\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.8514 -5.7544 -4.9397  4.0241  6.9925\n",
       "   0.3769  0.3978 -2.7889  2.4882  2.0899\n",
       "   5.0384  0.6526 -5.3972  7.0210  3.2918\n",
       "  -0.0387  7.1901  2.0426  3.2006 -8.1345\n",
       "  -1.7102 -1.9964  4.1667 -5.8626  0.8937\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.1651  7.7128  3.5062  5.5331 -5.0613\n",
       "  -2.6460 -0.8941  6.6874 -2.1946  0.9047\n",
       "  -3.1311  4.8148  4.1965  0.6479 -4.4188\n",
       "  -0.4253  0.7773  0.4768  6.0570  6.8693\n",
       "  -2.8010 -3.8796 -1.1763  0.8368 -0.9680\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.5278  3.9158  4.7636 -4.9018 -6.9977\n",
       "   5.6516  5.1457 -1.3820 -6.1465 -1.2411\n",
       "  -2.6880  3.2438 -1.3094 -8.0419 -4.2761\n",
       "  -0.0185  5.6404  0.0263  8.0522 -5.9625\n",
       "  -5.8466 -4.0093  0.0245  8.0391 -6.1860\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.6867 -0.6497 -1.6769  7.9405  7.2621\n",
       "   5.5106  1.1746 -0.6913 -1.0203 -7.3509\n",
       "   4.0548 -4.6921 -1.9486  0.8478  4.7279\n",
       "  -4.2292 -2.6866  1.0607 -4.9746 -5.0004\n",
       "   3.3336 -2.3163 -7.5198 -2.2446  3.6965\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.0794 -3.6834  7.5239  5.5624  2.2177\n",
       "  -1.4094  2.7631  4.8613 -1.7550  4.2350\n",
       "   0.5439 -1.3531  3.7262  7.9736  2.9272\n",
       "   4.4441 -1.7596 -5.5123 -7.9594 -6.9252\n",
       "  -7.2923 -2.7963 -6.8017 -5.2149 -6.0856\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.1296 -4.6819 -6.0200  0.5267  0.5072\n",
       "   6.7718 -3.0103 -1.9164  8.0846 -2.8230\n",
       "   7.5650 -1.6892  1.9675  4.5234 -6.4727\n",
       "   7.2358  7.8988 -7.2619  3.6398 -8.0504\n",
       "   2.5993 -6.0760  0.4340  3.0193  7.5539\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.7916 -8.1421 -1.3561 -2.0644  0.7939\n",
       "   0.6567 -1.7309  4.6786 -6.2291 -5.2090\n",
       "   0.6828 -2.2050  1.3917 -7.6963 -6.6520\n",
       "  -3.7258 -6.7393  8.0428 -2.3387 -2.1135\n",
       "   3.0770  2.2502 -5.4780 -5.7553  1.2954\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.6797  5.3197  0.4213  2.1371  4.0616\n",
       "  -6.2757 -7.8541  5.0236 -4.1426  6.1936\n",
       "  -4.5797  4.8704  6.4686 -3.8551 -6.5871\n",
       "   8.0014 -0.6105 -4.3362 -5.6485  0.1600\n",
       "   7.1069  3.0182  0.0816 -6.9493  1.0404\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.5648  4.9129 -5.7869 -6.4366 -1.4556\n",
       "   3.9822  7.9525  4.1238 -7.0774 -5.9416\n",
       "   3.6661 -3.9101  3.7738  0.1864  2.5526\n",
       "  -7.2789  0.0933 -1.8478  0.8213 -8.1104\n",
       "  -6.5473  0.9325  6.3088  2.2275 -5.1692\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.7534  6.2162 -2.1821  4.0747  7.8934\n",
       "   1.8061  5.1514  0.9871  4.1706  0.4322\n",
       "   0.6729 -0.1446 -1.3133  4.0104  4.0657\n",
       "   5.1308 -6.7009 -4.2188 -6.1391  4.5953\n",
       "  -6.2039 -4.4309 -2.2463 -4.6317 -0.0092\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.7518  5.3499  3.6291  3.5708  7.6606\n",
       "  -6.5064  3.9894  4.4339  6.4272 -6.6276\n",
       "  -3.4003 -0.6684  1.8800 -3.1105  4.5917\n",
       "   5.8517 -4.5822  1.2981  0.9305  6.3229\n",
       "  -2.2499 -0.2616  4.3070  3.1229  1.0862\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.1420 -4.1002  0.1282 -7.9893  7.9378\n",
       "   3.5262  1.9827 -3.5503 -1.4861 -2.1760\n",
       "   3.2495  5.0751 -1.8720 -2.6954 -3.5910\n",
       "   7.4044  1.3133  5.1536  2.6737  7.1528\n",
       "   6.9175  4.5069  5.0402 -7.8965 -1.6804\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.8427  1.9311 -1.2482 -0.0328  0.3519\n",
       "  -0.4776  1.0724  2.2487 -7.7345 -1.4503\n",
       "   7.8927  6.6231  3.9131 -4.7061  1.4253\n",
       "  -7.0497 -0.6864  1.2984 -4.5485 -6.0827\n",
       "  -1.1465 -8.1249 -3.9696 -1.5746  1.4481\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.3348  5.2092  3.6753  3.3772 -7.0496\n",
       "   1.0551 -2.7910 -6.2456 -7.6494 -3.1633\n",
       "  -2.0130 -5.3126 -3.5521 -2.2131 -6.3439\n",
       "  -7.5606 -6.8793 -6.6640 -1.1532 -2.7538\n",
       "  -1.5497 -3.3661 -1.0939  5.0624 -3.4871\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.7068  0.5656 -0.8350  3.7374 -4.6582\n",
       "   1.3603  7.7372 -1.8510  1.0524 -0.2861\n",
       "  -2.8012  0.6180  0.9048  3.1894  5.1916\n",
       "   3.2879  2.5486 -7.0955 -7.2273  7.7262\n",
       "  -1.8840  6.2822 -6.4459  3.1838 -1.8082\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.2828  3.6162 -6.2994 -0.1511  1.9552\n",
       "  -5.1168  4.5958  3.3657 -3.4734  6.2702\n",
       "  -7.2613 -3.0652 -7.8133 -3.6305 -4.5412\n",
       "   6.6296 -1.2211 -1.0699  7.4509  7.8859\n",
       "  -6.2097  0.2998 -2.9286  7.2291 -4.0418\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.2102  0.2699  7.2024  4.1458 -4.4333\n",
       "   5.3159  6.6495 -3.0504  6.6848 -4.0827\n",
       "   4.7128  7.8169 -2.9117  7.5134 -5.3700\n",
       "   5.2969 -5.7782  0.3123 -0.8821  0.5438\n",
       "   5.0418  5.6179  4.5693  7.4115  1.5196\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   8.1319 -6.3041 -7.2765  4.9261 -7.9323\n",
       "   6.3869 -0.3115 -4.8199 -6.7507 -1.5865\n",
       "   6.0978  0.4712  4.9844 -3.9945  3.4348\n",
       "  -6.4106  1.3504  7.7042  2.3462  3.5384\n",
       "  -6.6739 -2.1427  8.1335  5.6045  6.5425\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.1803  4.4222 -8.1609 -3.6732 -2.3816\n",
       "  -6.8038 -4.1521 -5.2820 -7.0517  0.3794\n",
       "  -1.5211  7.9412 -2.2625 -3.6977  7.9543\n",
       "  -7.2193  0.2633  4.9793 -5.5046 -6.4736\n",
       "  -2.1010  1.4319  4.9941  7.0188 -6.1749\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.0858  5.5877  6.5406  4.1088 -5.2061\n",
       "   7.8317 -7.4150 -5.0440 -0.0446  6.6136\n",
       "   3.5574  6.7125 -0.1508  0.3384  7.0152\n",
       "  -2.1053  1.2795 -7.7948 -7.1710  2.0587\n",
       "   7.3642 -7.6272 -6.2259  6.4593  7.8102\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.3879  0.5078  3.8882 -4.3659 -0.6385\n",
       "  -4.3744  4.5740 -3.7209 -6.8864 -3.1432\n",
       "   7.0345  2.9741  0.3394 -3.9414  2.9261\n",
       "   5.9051  7.3000  3.5850  1.1302 -6.2169\n",
       "  -6.0221  7.4202 -5.4011  2.2890  2.8152\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.7840 -1.2138 -2.0547  1.4188 -1.5046\n",
       "  -1.6803 -7.6935  6.0700  4.5607 -5.5645\n",
       "   8.1590  3.5649 -6.5767 -0.4537 -1.9898\n",
       "  -2.1235 -8.0412  0.3597 -4.0661  0.7573\n",
       "  -6.8222  7.3488  1.2677 -7.8020  2.3665\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.8245 -4.4932 -6.9520 -2.4529  6.4772\n",
       "   5.6009 -4.3586 -2.5420  3.7686 -1.6973\n",
       "  -2.6044  7.4576  7.9110  4.7552 -1.8595\n",
       "   0.6096 -5.6721 -2.6960 -3.3170  7.3209\n",
       "  -1.7005 -3.0332  7.0097  7.2730 -0.7780\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.2663  7.6104  4.4347 -2.7344 -3.7505\n",
       "   3.9491 -7.3372  0.0892 -2.4086 -1.6358\n",
       "  -1.8712  3.4716  4.8252  2.1741 -1.2685\n",
       "  -3.4960  5.2370 -2.9482  1.8569 -2.9043\n",
       "  -0.6650  0.1443 -5.2123  0.9806  6.4066\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.4621  5.2122 -5.5174  1.2099  2.9216\n",
       "   7.3985  8.0171 -6.2319 -6.7995  0.0628\n",
       "  -1.6854 -2.5038  4.0649  2.2945 -0.4154\n",
       "  -0.4306  8.0173  2.0334  3.2159 -6.6418\n",
       "   4.7561 -3.2923  7.6257  5.4480 -7.1923\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.2570 -6.1394 -4.5332  5.9650  5.8089\n",
       "   0.0908 -7.0626 -7.0091 -7.7707 -6.7857\n",
       "   2.2247 -6.4279  2.5471 -1.2756 -0.7163\n",
       "  -5.4572 -2.4405  0.6866 -5.6719 -1.1464\n",
       "  -6.4944 -2.5321 -1.8434  2.8438 -0.6938\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.5966  7.9002 -2.0177  0.0830  2.5091\n",
       "  -7.4185 -6.8742 -0.0388  4.1465  4.7889\n",
       "  -3.6551 -1.9432 -7.2504 -5.2281 -7.4972\n",
       "  -1.4119  2.2647  7.7102 -0.3423 -3.5237\n",
       "   4.7352 -3.7977 -0.0623 -7.3581  5.7564\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.4735  4.4648  5.0428 -5.3509  5.7836\n",
       "  -1.8461  2.9673  5.7546  0.9863  6.7219\n",
       "  -2.9419  6.0605 -1.0657 -1.6744  2.1954\n",
       "  -0.7533 -7.8489 -2.6646  2.5372  1.5574\n",
       "  -1.7069  1.8385 -1.2859  1.4441 -3.6067\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.1183 -1.0884  1.1950  5.6537 -6.4918\n",
       "  -0.9608 -5.9081 -2.5045  2.1663  4.1901\n",
       "  -3.6987  2.9078 -7.0698 -4.4751  0.8833\n",
       "   3.6497  0.1619  6.9015  0.2809 -8.0231\n",
       "  -6.2337 -1.9873 -2.3660  0.5165 -2.5056\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.7741 -5.9989  5.5836  4.2106 -6.2834\n",
       "   0.9466  0.2453  5.6814 -0.2192  3.9361\n",
       "  -6.6866 -0.3818  7.8062 -1.4050 -5.9410\n",
       "  -5.5720 -0.9590 -3.0002  7.6998  5.8658\n",
       "   5.9463  1.9815 -6.7072  6.7601  2.6774\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.0284  6.3512  6.5887  1.3131 -1.3636\n",
       "  -3.2461  6.1706 -7.3631 -2.7912  2.5449\n",
       "  -6.5696 -1.5598 -5.4633  5.7575  0.6674\n",
       "   6.5248  3.1156  7.3107 -0.5084 -1.0613\n",
       "  -2.6699  0.0033  6.3222  0.9363 -1.6475\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.9364  1.4955 -2.0713  8.0835  0.8779\n",
       "  -1.9137  1.6673  2.0409  5.2223  4.7819\n",
       "   7.4842  1.1576 -0.7272  2.3766 -5.1006\n",
       "  -6.5426 -3.2554 -2.9236  2.5067  0.1675\n",
       "  -3.0338 -3.1600  6.5321  4.4735  4.8707\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.0321 -7.3520 -7.8367 -0.9883  5.4585\n",
       "  -4.1548 -4.8789  4.9991 -0.4718  7.2285\n",
       "   0.6081 -7.7547  7.2265  2.2903  3.8525\n",
       "  -3.6861  7.9871  4.4464  6.3723  4.7846\n",
       "   2.0988 -4.2859  0.1278 -0.2916  2.7987\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.3058 -3.1527  2.0296 -0.9316  7.7295\n",
       "  -5.3248  1.3972  1.0230 -6.2543  1.2409\n",
       "  -4.1017 -7.1886 -0.1641  2.2202 -4.7415\n",
       "   0.4596 -6.0505 -2.8590  1.4245 -0.1220\n",
       "   0.2135 -0.0173 -2.9135 -6.6018 -6.2679\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.5612  1.1765 -6.9043 -0.2364  0.0779\n",
       "   4.5116  7.6723  3.1415 -3.1523  0.6823\n",
       "   1.1477  0.2318 -4.1131  7.3253 -3.7116\n",
       "   5.8333  4.3545  3.8054 -4.8613  1.6251\n",
       "  -7.9993  3.5061  2.2515  2.9814  2.7597\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   6.6482\n",
       "  -6.3868\n",
       "   2.2927\n",
       "   6.8138\n",
       "   7.7607\n",
       "  -1.4742\n",
       "   8.0346\n",
       "  -0.2257\n",
       "  -7.1735\n",
       "   0.2673\n",
       "  -6.3749\n",
       "   4.5383\n",
       "  -1.9074\n",
       "   1.2810\n",
       "  -0.8247\n",
       "  -6.2361\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       "  2.7918e-02  4.8692e-02 -3.9525e-02  ...   1.7965e-02 -3.3779e-02 -4.1699e-02\n",
       " -2.4715e-02 -4.0077e-02 -2.0228e-02  ...  -2.2520e-02  2.7894e-02 -4.2774e-02\n",
       "  2.8415e-02  1.5417e-02 -1.2192e-02  ...   1.6499e-02 -3.8892e-02 -2.9994e-02\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.3162e-02 -4.7173e-02 -1.2664e-02  ...   1.7921e-04  2.2113e-02 -9.5059e-03\n",
       " -6.4242e-04  3.9907e-02  1.7577e-02  ...   2.0150e-02 -5.6754e-03  8.7945e-03\n",
       "  3.1931e-02  3.0776e-02 -4.6935e-03  ...  -2.8569e-02 -4.2805e-03 -4.7795e-02\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   0.3078\n",
       "   1.2769\n",
       "  -3.7473\n",
       "  -1.8496\n",
       "  -2.4191\n",
       "   2.2286\n",
       "  -3.7386\n",
       "  -3.3297\n",
       "   0.1674\n",
       "   3.2604\n",
       "  -1.6186\n",
       "   4.1415\n",
       "   1.6040\n",
       "  -3.3154\n",
       "   2.8844\n",
       "   1.9100\n",
       "   3.3412\n",
       "   2.4749\n",
       "  -0.1639\n",
       "   0.7703\n",
       "   1.7507\n",
       "  -3.3268\n",
       "   4.8908\n",
       "   2.9414\n",
       "  -4.1272\n",
       "   2.8718\n",
       "  -4.4254\n",
       "   2.0792\n",
       "  -1.5936\n",
       "  -0.7045\n",
       "   3.1212\n",
       "   0.7270\n",
       "   4.0761\n",
       "   0.0879\n",
       "   1.4392\n",
       "  -1.7027\n",
       "   3.0468\n",
       "  -1.0047\n",
       "  -4.4282\n",
       "   4.2596\n",
       "  -0.2296\n",
       "  -4.8464\n",
       "   1.0762\n",
       "  -1.7926\n",
       "   1.7291\n",
       "   4.7860\n",
       "   4.2537\n",
       "   4.8525\n",
       "  -1.5900\n",
       "  -0.4632\n",
       "  -3.1835\n",
       "  -0.6132\n",
       "  -2.2867\n",
       "  -2.2893\n",
       "  -0.6608\n",
       "   0.4310\n",
       "  -1.9409\n",
       "  -3.6285\n",
       "  -0.3144\n",
       "   2.6714\n",
       "   3.0456\n",
       "  -0.7225\n",
       "   0.8294\n",
       "  -4.9085\n",
       "   0.4217\n",
       "  -4.9846\n",
       "   1.9269\n",
       "  -3.6292\n",
       "  -2.1830\n",
       "  -3.6395\n",
       "   2.9886\n",
       "  -0.4344\n",
       "   3.8268\n",
       "  -1.4033\n",
       "   1.7588\n",
       "  -2.9678\n",
       "   1.6109\n",
       "   4.7355\n",
       "   0.7939\n",
       "   0.3227\n",
       "  -1.5246\n",
       "  -4.5645\n",
       "   0.3823\n",
       "  -3.1271\n",
       "   0.1897\n",
       "   1.9094\n",
       "   1.4195\n",
       "  -0.1063\n",
       "  -0.6719\n",
       "  -4.9783\n",
       "  -3.1031\n",
       "  -4.2844\n",
       "   1.7161\n",
       "   1.4912\n",
       "   3.3295\n",
       "   2.1542\n",
       "  -4.7979\n",
       "   1.5839\n",
       "  -4.0806\n",
       "  -2.7254\n",
       "   1.0541\n",
       "  -0.5834\n",
       "   4.7162\n",
       "   0.5331\n",
       "  -4.1756\n",
       "  -1.8924\n",
       "   4.4911\n",
       "  -4.7639\n",
       "  -4.6393\n",
       "   3.9714\n",
       "   2.6316\n",
       "  -2.8636\n",
       "  -4.4208\n",
       "   2.5246\n",
       "  -4.7796\n",
       "  -0.0736\n",
       "  -2.7175\n",
       "  -1.8733\n",
       "  -2.0291\n",
       "   1.7676\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  1.9304 -5.7475  8.9213  ...  -2.4880 -6.1840 -3.6263\n",
       " -4.0729 -4.0292  8.5451  ...   0.3624  7.5348 -6.8721\n",
       "  7.0241  2.9136  8.0569  ...   4.6925 -3.0004 -7.1274\n",
       "           ...             ⋱             ...          \n",
       " -0.9138  4.4212  0.2395  ...  -1.3627 -3.0618  3.5101\n",
       "  2.6835 -8.1293  6.3893  ...   8.8352 -9.1253  4.0202\n",
       " -9.1263  7.3723 -1.2711  ...  -2.0093 -6.5271 -3.1942\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   1.7789\n",
       "  -5.3156\n",
       "  -6.6359\n",
       "  -2.6795\n",
       "   2.7404\n",
       "  -7.4414\n",
       "   0.9993\n",
       "   2.4603\n",
       "  -7.6671\n",
       "   2.1321\n",
       "   3.1811\n",
       "  -7.0741\n",
       "  -5.0716\n",
       "   4.8989\n",
       "   6.2928\n",
       "  -7.7896\n",
       "   6.5649\n",
       "   8.7480\n",
       "   0.0872\n",
       "   6.9809\n",
       "  -7.2428\n",
       "  -3.0009\n",
       "  -0.6383\n",
       "   4.1354\n",
       "   2.3979\n",
       "  -8.3487\n",
       "   0.9346\n",
       "   3.8166\n",
       "  -9.1044\n",
       "  -0.6065\n",
       "  -5.0518\n",
       "  -4.8919\n",
       "  -5.4632\n",
       "  -9.0888\n",
       "   1.5153\n",
       "   6.7579\n",
       "  -7.1335\n",
       "  -5.8250\n",
       "   0.0104\n",
       "   1.3411\n",
       "  -0.2761\n",
       "  -8.6345\n",
       "  -1.5004\n",
       "   7.7401\n",
       "   6.4347\n",
       "  -7.2144\n",
       "  -4.2605\n",
       "  -2.3177\n",
       "  -2.3653\n",
       "  -6.7944\n",
       "  -3.3725\n",
       "  -4.7253\n",
       "  -5.6399\n",
       "  -4.0468\n",
       "   6.3126\n",
       "   4.7191\n",
       "  -0.6388\n",
       "  -6.8007\n",
       "  -6.4749\n",
       "   8.1805\n",
       "   3.1967\n",
       "   8.7307\n",
       "  -6.1772\n",
       "   5.1562\n",
       "   2.2625\n",
       "   1.1698\n",
       "   4.7147\n",
       "   4.3233\n",
       "   8.3389\n",
       "   8.5027\n",
       "  -7.3371\n",
       "  -6.4397\n",
       "  -4.5516\n",
       "   0.4212\n",
       "   8.7632\n",
       "  -2.1884\n",
       "  -6.2710\n",
       "   4.3979\n",
       "  -8.7052\n",
       "   8.9153\n",
       "  -5.6162\n",
       "   2.9731\n",
       "   6.0194\n",
       "   8.0549\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       "  0.0721 -0.0127  0.1060  0.0303 -0.0227 -0.0932  0.0234  0.0634 -0.0451 -0.0948\n",
       "  0.0754  0.0901 -0.0525 -0.0818  0.0980  0.0455  0.0262 -0.0006 -0.0803 -0.0672\n",
       " -0.0832  0.0601 -0.0264  0.0814 -0.1073 -0.0304  0.0014  0.0539  0.0807 -0.0254\n",
       "  0.1012 -0.0647  0.0199  0.0190 -0.0752  0.0535 -0.0256  0.0427  0.0653  0.0541\n",
       "  0.0135  0.1015 -0.0564 -0.0631  0.0915 -0.0917  0.0986 -0.0439  0.0232  0.0291\n",
       " -0.0542 -0.1054  0.0584 -0.0706 -0.0408 -0.1057 -0.0979  0.0490 -0.0669  0.0100\n",
       " -0.0263 -0.0122  0.0101 -0.0558  0.0321  0.0039  0.0991  0.0899  0.0211  0.0004\n",
       "  0.0720 -0.0774 -0.0838  0.0461  0.0198  0.0235  0.0949  0.0967 -0.0587 -0.0707\n",
       " -0.0219  0.0847 -0.0444  0.0690  0.0959 -0.0141  0.0624 -0.0653  0.0699 -0.0975\n",
       "  0.0863 -0.0635 -0.1045  0.0424 -0.0813 -0.0418  0.0821 -0.0651  0.0771 -0.0770\n",
       " \n",
       " Columns 10 to 19 \n",
       " -0.0513  0.0527  0.0222  0.0805 -0.0570  0.0664  0.0496  0.1002  0.0856 -0.0302\n",
       "  0.1018  0.0620  0.0928  0.0052 -0.0024 -0.1055  0.0561 -0.0059 -0.0488 -0.0858\n",
       " -0.0858 -0.0784  0.0986  0.0730  0.0996  0.0843 -0.0123  0.0738 -0.0715  0.0725\n",
       "  0.0372 -0.0815  0.0379 -0.0678 -0.0049 -0.1075 -0.0386  0.0790 -0.1054  0.0841\n",
       "  0.0505 -0.0735 -0.0726 -0.0301 -0.0121  0.0857 -0.0608 -0.0390  0.1002 -0.0786\n",
       " -0.0836  0.0787  0.0286 -0.0115  0.0704 -0.0559 -0.0716 -0.1062 -0.1053 -0.0834\n",
       "  0.0453  0.0697 -0.0862 -0.1037 -0.0031 -0.0182 -0.0853 -0.0164 -0.0653  0.1010\n",
       " -0.0839 -0.0488 -0.0597 -0.0922 -0.0590 -0.0368 -0.0450 -0.0211 -0.0246 -0.1073\n",
       "  0.0946  0.1028 -0.0881  0.0493  0.0362 -0.0972  0.0900 -0.0601  0.0979  0.0333\n",
       " -0.0521 -0.0931 -0.0728 -0.0195 -0.0010  0.0892 -0.0107  0.0047  0.0329 -0.0690\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.0926  0.0392 -0.0840 -0.0421  0.0005 -0.0508  0.0763  0.0846 -0.0987 -0.0591\n",
       "  0.0976  0.0755  0.0096  0.0666 -0.0200 -0.0309 -0.0409 -0.0168  0.0931 -0.0294\n",
       " -0.0157  0.0227 -0.0549 -0.1073  0.0140  0.0086  0.0193  0.0638  0.0459  0.0933\n",
       " -0.0961 -0.0220 -0.0615 -0.0605 -0.0693 -0.0093 -0.0949 -0.0584 -0.0865 -0.0425\n",
       "  0.0183  0.0762 -0.0398 -0.1072  0.1080 -0.0402 -0.0592  0.1045  0.0233  0.0822\n",
       " -0.0344 -0.0291 -0.0017 -0.0659  0.0438 -0.0610 -0.0237  0.0561 -0.0779  0.0947\n",
       "  0.0444 -0.0766  0.0111  0.0434 -0.0666  0.0263 -0.0166  0.0028 -0.1008  0.0081\n",
       " -0.0411 -0.0599  0.0080  0.0879 -0.0464  0.0502  0.0591  0.0163  0.0473 -0.1022\n",
       " -0.0672  0.0639  0.0205 -0.0653 -0.0000 -0.0940 -0.0124  0.0306  0.0085 -0.0351\n",
       "  0.0435 -0.0663  0.0675  0.0359  0.0202 -0.0870  0.0446 -0.1038 -0.0407 -0.0972\n",
       " \n",
       " Columns 30 to 39 \n",
       "  0.0469 -0.0089 -0.0732 -0.0721  0.1038  0.0456  0.0019  0.0050  0.0749 -0.0881\n",
       " -0.0982 -0.0752  0.0609 -0.0474  0.0804  0.0913 -0.0725 -0.0123 -0.0562  0.0020\n",
       "  0.0728  0.0718  0.0943 -0.0271  0.0278  0.0174  0.0825  0.0741 -0.0887  0.0936\n",
       " -0.0121  0.0059 -0.0779  0.0122 -0.0388  0.0844  0.0390 -0.0997  0.0639  0.0186\n",
       "  0.1009  0.0430  0.0596 -0.0971 -0.0660  0.0471 -0.0950 -0.0588  0.0102 -0.1014\n",
       "  0.0699 -0.0561 -0.0835 -0.0954  0.0867 -0.0962  0.1048 -0.0720 -0.0763  0.0484\n",
       " -0.1042 -0.0547 -0.0829 -0.0155 -0.0616  0.0402  0.0220 -0.0001 -0.0221  0.0972\n",
       " -0.0895 -0.0775 -0.0694  0.1042  0.0730 -0.0880 -0.0762 -0.0766 -0.0350 -0.0817\n",
       "  0.0463 -0.0416 -0.0408 -0.0676 -0.0466  0.0251 -0.0997  0.0449 -0.0775  0.0970\n",
       " -0.1055 -0.0186 -0.0549  0.0353 -0.0311 -0.0329 -0.1021 -0.0396  0.0674  0.0604\n",
       " \n",
       " Columns 40 to 49 \n",
       " -0.0998 -0.0648 -0.0600 -0.1084 -0.0469 -0.0770  0.0226  0.0574  0.0962 -0.0453\n",
       " -0.0633  0.0807  0.0839 -0.0052  0.1049 -0.0580  0.0546 -0.0284 -0.0366 -0.0226\n",
       " -0.1019 -0.0418  0.0174 -0.0725  0.0058  0.0615 -0.0543  0.0740 -0.0248 -0.0664\n",
       "  0.0156  0.0841 -0.0176 -0.0858 -0.0454 -0.0621  0.0425  0.0752 -0.0656  0.0486\n",
       " -0.0704 -0.0627  0.0344  0.0061 -0.1043 -0.0836  0.0054  0.0290 -0.0299  0.0623\n",
       "  0.0515 -0.0531  0.0902  0.0386  0.0992 -0.0605 -0.0442  0.0447 -0.0033  0.0246\n",
       " -0.0656  0.0148 -0.0015 -0.0471 -0.0093 -0.0245 -0.0004 -0.0396  0.0857  0.0924\n",
       "  0.0210 -0.0834 -0.0470 -0.0918 -0.0355  0.1034  0.0414 -0.0999  0.0530  0.0660\n",
       "  0.0850 -0.1055 -0.0877 -0.0389  0.0240  0.0591  0.0649  0.0275  0.0564 -0.0593\n",
       " -0.0683  0.0884  0.0898  0.0388 -0.0543  0.0343  0.0306 -0.0536  0.0998 -0.1071\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.0380 -0.1081 -0.0261 -0.0601 -0.0789  0.0376 -0.0632 -0.1057 -0.0901  0.0961\n",
       " -0.0387  0.0986 -0.0455 -0.0750 -0.0306 -0.0170 -0.0741 -0.0373 -0.0968  0.0746\n",
       "  0.0933  0.0682 -0.0615 -0.0767 -0.0156 -0.1012  0.0590  0.0506 -0.0743 -0.0848\n",
       " -0.0465 -0.0247  0.0006 -0.0894  0.0118  0.0708 -0.0034 -0.0724  0.0962 -0.0339\n",
       "  0.0861 -0.0014 -0.0849 -0.0139 -0.0736 -0.0716  0.1056  0.0959  0.0107 -0.0493\n",
       " -0.0178 -0.0996 -0.0972 -0.0959  0.0832  0.0593  0.0998  0.0560 -0.0977 -0.0324\n",
       " -0.0234 -0.0821 -0.0454 -0.0709 -0.0759  0.0818  0.0389 -0.0938 -0.0777  0.0930\n",
       " -0.0810 -0.0642 -0.0573 -0.0104  0.1068  0.0539 -0.1071 -0.0631 -0.0610 -0.0807\n",
       "  0.0120  0.0922 -0.0698  0.0650  0.0615 -0.0537 -0.0168 -0.0667 -0.0385 -0.0454\n",
       "  0.0723 -0.0840 -0.0002  0.0950 -0.0094  0.0525  0.0464  0.0574  0.0779 -0.0334\n",
       " \n",
       " Columns 60 to 69 \n",
       " -0.0022  0.0116 -0.0152 -0.0733 -0.0431  0.0577 -0.0257 -0.0148  0.0763  0.0329\n",
       "  0.0370  0.0543  0.0500 -0.0623 -0.0544  0.0514 -0.0243 -0.0372 -0.0063 -0.0200\n",
       " -0.0773 -0.1027 -0.0512 -0.0108 -0.0838  0.0805  0.0531 -0.0032 -0.0289  0.0853\n",
       "  0.0059  0.1074  0.1010  0.0131 -0.0372  0.0223 -0.0535  0.0589  0.0347  0.0756\n",
       " -0.0748  0.0359  0.0248 -0.0077  0.0357 -0.0299 -0.0905 -0.0223  0.0050 -0.0797\n",
       " -0.0447  0.0414  0.0570  0.0290 -0.0882  0.0652 -0.0526 -0.0553 -0.0885  0.0964\n",
       " -0.0188 -0.0716 -0.0165 -0.0522  0.1065  0.0915 -0.1078  0.0120  0.0987 -0.0794\n",
       "  0.0235 -0.0271  0.0985  0.0437 -0.0046  0.0879  0.0797 -0.0808  0.0361 -0.0776\n",
       "  0.0171  0.0192 -0.0255 -0.1052  0.0512 -0.0549 -0.0300 -0.0356 -0.0630  0.0841\n",
       "  0.0891 -0.0057  0.0295 -0.0566 -0.1088 -0.0012 -0.0125  0.0795  0.1042  0.0631\n",
       " \n",
       " Columns 70 to 79 \n",
       " -0.1029  0.0043  0.0524 -0.0484 -0.1067  0.0984 -0.0737 -0.0576  0.0887  0.0705\n",
       " -0.0139 -0.0644 -0.0600 -0.0796  0.0092 -0.0751 -0.0190 -0.0183  0.0095  0.0415\n",
       " -0.0922 -0.0389 -0.0718 -0.0067  0.0177  0.0732 -0.0060 -0.0943 -0.0944  0.1027\n",
       "  0.0180  0.0548 -0.0096 -0.0895 -0.0435 -0.0419  0.0262 -0.0621  0.0407 -0.0041\n",
       " -0.0501  0.0724  0.0854 -0.1049  0.0965  0.0110 -0.0252  0.0282  0.0762  0.0171\n",
       " -0.0485  0.0584 -0.1011 -0.0055  0.0340  0.0922  0.0356 -0.0575 -0.0546 -0.0815\n",
       "  0.0010  0.0406 -0.0852  0.0539 -0.0696  0.0927  0.0637  0.0950 -0.0556  0.0592\n",
       " -0.0151  0.0472  0.0410  0.0762  0.0497 -0.0497 -0.0919  0.0374 -0.0931 -0.0688\n",
       "  0.0229  0.0521 -0.0410 -0.0363 -0.0918  0.0664  0.0055 -0.0308  0.0509 -0.0193\n",
       " -0.0503  0.0476 -0.0173  0.0209  0.0327 -0.0389  0.0179 -0.0266  0.0866  0.0339\n",
       " \n",
       " Columns 80 to 83 \n",
       " -0.0854 -0.1090  0.0280  0.1014\n",
       "  0.0571 -0.0448 -0.0282  0.0096\n",
       " -0.0088  0.0721  0.1061  0.0494\n",
       " -0.1048  0.0453  0.0531 -0.0959\n",
       "  0.0608  0.0978 -0.0731 -0.0343\n",
       "  0.0044 -0.0583 -0.0345  0.0051\n",
       " -0.0832  0.0636 -0.1081  0.0580\n",
       "  0.0213 -0.0509  0.0798  0.0392\n",
       "  0.0847 -0.0257 -0.0917 -0.0605\n",
       " -0.0852  0.0364 -0.0663 -0.0902\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -0.1897\n",
       "  -0.1275\n",
       "   1.2499\n",
       "   9.4681\n",
       "   1.5758\n",
       "  -6.2188\n",
       "   1.7653\n",
       "   8.0398\n",
       "  -2.9784\n",
       "   7.9218\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.0546 -0.1738  0.0171  0.1902 -0.0517\n",
       "  0.1902 -0.0532 -0.1967 -0.0101  0.0939\n",
       " -0.1014  0.0888  0.0987  0.1674  0.0987\n",
       " -0.0375  0.0479  0.0106 -0.0430  0.0486\n",
       " -0.0876  0.0446  0.1501 -0.1480  0.1991\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -0.0192  0.1092 -0.1625  0.0245  0.0810\n",
       " -0.0461 -0.1366 -0.1793 -0.0824  0.0087\n",
       "  0.1822  0.0776 -0.0629  0.1958  0.0443\n",
       " -0.1477  0.0562 -0.0781  0.1526 -0.0988\n",
       "  0.1778  0.1572  0.0561  0.1521 -0.0874\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " -0.1381  0.1707  0.0515 -0.0099 -0.1072\n",
       "  0.1631  0.1355  0.0371  0.0874 -0.1071\n",
       " -0.0611 -0.0064 -0.0513 -0.0554 -0.1933\n",
       "  0.0645  0.1497 -0.0412  0.1253 -0.0288\n",
       "  0.0098 -0.1112  0.1924  0.1041  0.0813\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       " -0.0318  0.1625  0.1289 -0.0844 -0.1232\n",
       "  0.1451 -0.0838  0.0380  0.1754  0.0872\n",
       " -0.0790  0.1047 -0.1569 -0.0257  0.0543\n",
       "  0.1333  0.0690  0.1368 -0.1472  0.1646\n",
       "  0.1891 -0.1897  0.1361 -0.0883  0.0209\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       " -0.0420  0.0543  0.1606  0.1331 -0.0562\n",
       "  0.1034 -0.1384 -0.1328  0.1412  0.0238\n",
       " -0.0629 -0.0635 -0.1518 -0.0051  0.0183\n",
       "  0.0464  0.0317 -0.0389 -0.1163  0.0675\n",
       " -0.0463 -0.0740  0.0081  0.0127 -0.0584\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       " -0.0668  0.0453  0.1748  0.1024 -0.0946\n",
       "  0.0326  0.1854  0.0911 -0.0126 -0.0345\n",
       "  0.0246  0.0768 -0.0003 -0.0253 -0.0753\n",
       " -0.0991  0.0392 -0.0620 -0.1306 -0.0972\n",
       "  0.1569  0.0652  0.1008 -0.1757  0.0598\n",
       "[torch.FloatTensor of size 6x1x5x5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0064  0.0116  0.0367  0.0716 -0.0185 -0.1230 -0.0216  0.0586 -0.0585  0.0949\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic forward and backward propagation\n",
    "input = Variable(torch.randn(1,1,32,32))\n",
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/__init__.py:93: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10), retain_variables = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Summary so far\n",
    "- Torch.Tensor is a multi-dimensional array\n",
    "- autograd.Variable - Tensor + History + backwards + gradient object\n",
    "- nn.Module - neural net encapsulation\n",
    "- autograd.function - implementation of forward and baackwrds prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "out = net(input)\n",
    "target = Variable(torch.range(1,10))\n",
    "crit = nn.MSELoss()\n",
    "loss = crit(out, target)\n",
    "nll = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.9303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.7469\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.5824\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.4150\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.2650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  3.1126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.9755\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.8367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.7108\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.5840\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.4696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.3551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.2513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.1472\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  2.0519\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.9563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.8699\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.7836\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.7036\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.6245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.5524\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.4812\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.4158\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.3494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.2870\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.2255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.1701\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.1160\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.0661\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      "  1.0164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  9.7063\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  9.2659\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  8.8562\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  8.4429\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  8.0572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  7.6854\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  7.3480\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  7.0133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  6.7006\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  6.3959\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  6.1079\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  5.8261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  5.5644\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  5.3071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  5.0696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  4.8420\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  4.6274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  4.4116\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  4.2116\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  4.0194\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.8397\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.6635\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.4977\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.3386\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.1852\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  3.0368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.9006\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.7684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.6435\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.5220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.4067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.2967\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.1917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  2.0879\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.9931\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.9004\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.8126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.7275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.6503\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.5741\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.5026\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.4320\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.3645\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.3031\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.2474\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.1911\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.1364\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.0838\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-07 *\n",
      "  1.0322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  9.8276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  9.3577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  8.8997\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  8.4890\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  8.0975\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  7.7267\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  7.3634\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  7.0165\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  6.7092\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  6.4261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  6.1345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  5.8564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  5.5899\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  5.3546\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  5.1303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  4.9172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  4.6969\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  4.4776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  4.2729\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  4.0881\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-08 *\n",
      "  3.9101\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJalxBr0kNc6gl6TGGfSS1Lj/B2Moa3l+GVW0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113aa3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "lr = 0.01\n",
    "losses = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(input)\n",
    "    loss = crit(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    losses.append(loss.data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(losses, [i for i in range(len(losses))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
