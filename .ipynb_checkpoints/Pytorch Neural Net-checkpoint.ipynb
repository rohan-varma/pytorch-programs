{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from __future__ import print_function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(5,3) # constructs a 5 x 3 uniitialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3) # constructs a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8719  0.3786  0.9879\n",
       " 0.8765  0.7764  0.1657\n",
       " 0.9829  0.4654  0.9760\n",
       " 0.0948  0.9852  0.9190\n",
       " 0.8051  0.0162  0.2386\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5L"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8010  0.3063  1.5117  1.2059  0.2385  0.7285  0.6124  0.8504  0.9714  1.3248\n",
       " 1.3608  0.6049  1.0347  1.2128  0.4826  1.1395  1.0347  1.4147  0.6919  0.7753\n",
       " 1.6030  0.7805  1.4271  1.1507  1.2512  0.4831  1.0327  1.5224  0.8334  0.4188\n",
       " 1.9166  1.4121  1.4808  0.9519  0.9422  0.6243  1.1294  1.1226  1.3079  1.1661\n",
       " 1.5050  0.2677  1.4910  1.3543  1.2135  0.6822  1.1575  0.2612  0.9184  0.9659\n",
       " 1.0027  0.3636  0.3761  0.4027  0.7455  0.7840  0.5258  1.3006  1.4122  1.4242\n",
       " 0.7979  0.4516  1.4584  1.2698  0.5359  0.9427  0.8881  0.9737  0.5724  0.3532\n",
       " 0.6757  1.0396  0.8387  1.3520  1.4407  1.6282  1.1520  1.4749  0.7469  1.3922\n",
       " 0.6446  0.9557  1.0857  0.7361  0.3066  1.2318  1.3502  0.6107  1.5107  0.8731\n",
       " 1.5047  0.8605  0.9848  1.1782  0.4186  0.6731  1.2465  0.5590  0.0279  1.0344\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = torch.rand(10, 10), torch.rand(10, 10)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8010  0.3063  1.5117  1.2059  0.2385  0.7285  0.6124  0.8504  0.9714  1.3248\n",
       " 1.3608  0.6049  1.0347  1.2128  0.4826  1.1395  1.0347  1.4147  0.6919  0.7753\n",
       " 1.6030  0.7805  1.4271  1.1507  1.2512  0.4831  1.0327  1.5224  0.8334  0.4188\n",
       " 1.9166  1.4121  1.4808  0.9519  0.9422  0.6243  1.1294  1.1226  1.3079  1.1661\n",
       " 1.5050  0.2677  1.4910  1.3543  1.2135  0.6822  1.1575  0.2612  0.9184  0.9659\n",
       " 1.0027  0.3636  0.3761  0.4027  0.7455  0.7840  0.5258  1.3006  1.4122  1.4242\n",
       " 0.7979  0.4516  1.4584  1.2698  0.5359  0.9427  0.8881  0.9737  0.5724  0.3532\n",
       " 0.6757  1.0396  0.8387  1.3520  1.4407  1.6282  1.1520  1.4749  0.7469  1.3922\n",
       " 0.6446  0.9557  1.0857  0.7361  0.3066  1.2318  1.3502  0.6107  1.5107  0.8731\n",
       " 1.5047  0.8605  0.9848  1.1782  0.4186  0.6731  1.2465  0.5590  0.0279  1.0344\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.Tensor(10, 10)\n",
    "torch.add(x, y, out=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8010  0.3063  1.5117  1.2059  0.2385  0.7285  0.6124  0.8504  0.9714  1.3248\n",
       " 1.3608  0.6049  1.0347  1.2128  0.4826  1.1395  1.0347  1.4147  0.6919  0.7753\n",
       " 1.6030  0.7805  1.4271  1.1507  1.2512  0.4831  1.0327  1.5224  0.8334  0.4188\n",
       " 1.9166  1.4121  1.4808  0.9519  0.9422  0.6243  1.1294  1.1226  1.3079  1.1661\n",
       " 1.5050  0.2677  1.4910  1.3543  1.2135  0.6822  1.1575  0.2612  0.9184  0.9659\n",
       " 1.0027  0.3636  0.3761  0.4027  0.7455  0.7840  0.5258  1.3006  1.4122  1.4242\n",
       " 0.7979  0.4516  1.4584  1.2698  0.5359  0.9427  0.8881  0.9737  0.5724  0.3532\n",
       " 0.6757  1.0396  0.8387  1.3520  1.4407  1.6282  1.1520  1.4749  0.7469  1.3922\n",
       " 0.6446  0.9557  1.0857  0.7361  0.3066  1.2318  1.3502  0.6107  1.5107  0.8731\n",
       " 1.5047  0.8605  0.9848  1.1782  0.4186  0.6731  1.2465  0.5590  0.0279  1.0344\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autograd is a tensor-based automatic differentiation library. Autograd requires data of types Variable and Function to build up a computation graph. You can use ```.backward()``` to compute derivatives for backprop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd._functions.basic_ops.AddConstant at 0x10a637e60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27  27\n",
       " 27  27\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 3*(y**2) # a basic function\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out.backward(retain_variables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.5000  4.5000\n",
       " 4.5000  4.5000\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Neural Nets in Pytorch\n",
    "- Use ```torch.nn``` package. \n",
    "- NN depends on autograd to differentiate nn loss functions\n",
    "- nn.Module contais layers, and the method forward returns outputs. \n",
    "- Neural Network roadmap:\n",
    "    - Define net that has some learnable weights\n",
    "    - propogate input through the network\n",
    "    - compute the loss function\n",
    "    - compute partial derivatives with respect to the weights and use the backpropagation algorithm to update the weights\n",
    "    - weight update: weight = weighted - (learning rate $*$ gradient + momentum_cost $*$ prev_grad). \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear (400 -> 120)\n",
       "  (fc2): Linear (120 -> 84)\n",
       "  (fc3): Linear (84 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object parameters at 0x10a9cdd20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0992  0.1677 -0.1258  0.0381  0.0935\n",
       "  -0.1119  0.0292  0.0019  0.1882 -0.1174\n",
       "   0.0381  0.1954  0.0352 -0.0662 -0.0212\n",
       "  -0.0932 -0.1167  0.1073 -0.0009  0.1536\n",
       "  -0.1049  0.1667  0.0398 -0.0735 -0.1644\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.1478 -0.0086  0.0004  0.0514  0.0919\n",
       "   0.1457 -0.0984  0.0095 -0.1063 -0.1642\n",
       "  -0.1211 -0.0235 -0.1344  0.1966 -0.1802\n",
       "  -0.1462  0.1145  0.1714 -0.1523 -0.1133\n",
       "  -0.1520  0.1304 -0.0317 -0.1527  0.1538\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "   0.0733  0.1316  0.1687 -0.0617  0.1013\n",
       "   0.1343 -0.0202 -0.0492  0.1115  0.1382\n",
       "  -0.1112 -0.1679  0.1365  0.1945  0.0409\n",
       "   0.1372 -0.1470  0.1027 -0.0408  0.0516\n",
       "  -0.0901 -0.0411 -0.0677 -0.1372 -0.0567\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.1641  0.0936 -0.1168  0.0829  0.0724\n",
       "   0.1183  0.1898  0.1678 -0.0585 -0.1817\n",
       "  -0.1199  0.1507  0.1504 -0.1702  0.0586\n",
       "  -0.1399 -0.1842 -0.0353  0.0875 -0.1266\n",
       "   0.0528 -0.1486  0.1896  0.1766  0.1904\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "   0.1848  0.0359  0.1397 -0.1356 -0.1437\n",
       "   0.0207  0.1274  0.0827 -0.1108  0.0419\n",
       "   0.1083 -0.0749 -0.1973  0.1260 -0.1922\n",
       "   0.1563  0.0226  0.1965  0.1543  0.0348\n",
       "  -0.0128  0.1305  0.0338  0.1625  0.0935\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "   0.1600  0.0999  0.1234  0.0052 -0.1074\n",
       "  -0.0755  0.1480 -0.1497  0.1177 -0.1509\n",
       "   0.0845 -0.1669 -0.0591  0.1730  0.1089\n",
       "   0.0914  0.0534 -0.1195 -0.1644 -0.1105\n",
       "  -0.0835  0.1830 -0.0167  0.1945 -0.0441\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       "  0.0485\n",
       "  0.0124\n",
       " -0.1853\n",
       "  0.1242\n",
       " -0.0533\n",
       " -0.0123\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.1832 -1.5895  4.3330 -7.9730 -5.0525\n",
       "   0.1426  7.0601  7.1689 -4.5812 -7.5483\n",
       "   1.6695 -3.5006  1.5829 -5.6840  1.0802\n",
       "   7.2864 -3.6590 -5.1065 -6.4813  0.5085\n",
       "  -2.0133  1.7322 -0.4555  5.3958  4.4535\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.4260  7.2798  6.8431 -0.0894 -1.8174\n",
       "   3.6829  1.8727 -5.3744  0.6649  4.6742\n",
       "   6.6609  2.0141 -4.9090 -7.4180  2.6540\n",
       "   1.5141  0.6772  6.1232  3.9068  5.6554\n",
       "   4.2615  1.3688 -0.1416  0.4864 -2.8725\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.0641 -4.6495 -1.0139  0.7999  1.4853\n",
       "  -2.9699 -0.6316 -1.7821 -0.8019 -3.9400\n",
       "  -0.8224 -7.0154  4.4479  6.7248 -4.3039\n",
       "  -2.1298 -0.5619 -0.6054 -1.5477  5.9336\n",
       "   1.2548 -4.9762  4.3332 -1.0104  2.0873\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.0610  1.3251  2.8272  7.5645 -1.3735\n",
       "  -1.0865  6.7618 -7.0653 -4.3125 -3.4808\n",
       "  -7.1386 -0.4546  2.8034 -2.0366 -0.5434\n",
       "  -3.6369  2.0487 -0.6771  5.9480 -6.9797\n",
       "  -2.7863 -1.9976 -5.5512 -2.1598  1.5968\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.0238 -0.7782  2.5356 -0.6775 -2.4203\n",
       "  -3.0388  8.1455 -2.2718 -3.6337 -2.5025\n",
       "   7.9882 -7.0313 -3.8888  3.5665  5.0863\n",
       "   0.4282  4.1334  6.3161  1.4167 -7.0887\n",
       "  -1.3895 -6.4353 -0.3309  3.9703 -5.8103\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.9662  6.4991 -3.3626  0.6591 -3.9420\n",
       "  -5.5665  3.2684  5.4256 -5.6165 -5.2147\n",
       "   6.9743 -3.9325  0.4167 -7.6483  6.7013\n",
       "   1.8197 -8.0441 -1.4249 -4.1433 -5.9345\n",
       "   5.2750 -2.0430  1.8618  5.7476 -5.4558\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.3814 -1.1280 -1.6101 -7.9461  6.2375\n",
       "   4.8366 -1.1957 -1.6949 -0.6252 -0.3556\n",
       "  -7.3935  6.0831  2.9227 -6.3449  6.1808\n",
       "  -1.3803  7.8984  3.6892 -6.8806 -0.0606\n",
       "  -2.3495 -1.8323 -1.8578  5.4497  5.6235\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.5773  4.7640  0.4582 -6.8518  6.7426\n",
       "   4.0566 -2.4741  5.0289 -1.0306  3.2490\n",
       "   2.5364  3.1400 -3.7222 -0.0950  3.8306\n",
       "   6.3599  6.4812  3.3097  5.4570  3.0113\n",
       "  -5.7449 -7.6528  5.3795 -5.0421  7.3181\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.0282  5.4159  4.7935  4.4905  6.8724\n",
       "   4.3934 -6.7386 -0.2658 -3.8783 -5.0003\n",
       "   8.1570 -0.5764 -0.3772 -7.9457  4.5336\n",
       "  -7.0234 -5.8086 -6.2060 -7.2575  1.1228\n",
       "  -6.4245  0.3682  3.9728 -0.8884  6.5991\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.9999 -5.7950 -4.2801 -2.2990  7.4403\n",
       "   7.3422  5.8207 -3.7866 -5.8918  1.0083\n",
       "  -7.6059 -3.6733 -1.7346  2.2536 -1.9025\n",
       "  -1.7051  2.3590  3.5464  6.7913 -7.4008\n",
       "  -7.9064  3.8482  0.1884  6.1753 -2.4476\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.7430 -0.4193 -0.1107 -4.1869 -0.7888\n",
       "   0.0769 -2.5231 -8.1240 -7.0903  5.1494\n",
       "  -5.1349 -7.1700  7.1082 -0.6430 -0.9927\n",
       "   3.7216  6.8176  8.0489  2.2653  2.4795\n",
       "   1.2636 -2.3299 -5.0071  0.7486 -2.8236\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.1976 -5.7498  2.6102  8.1272  3.7768\n",
       "   4.3948  3.2454  5.8287 -8.1547 -5.2445\n",
       "   4.4528 -1.3059 -2.0668 -0.3363 -5.0417\n",
       "  -2.3536 -1.4887 -6.1911 -5.9945 -2.0274\n",
       "  -1.5739 -3.4495  5.0606  4.9962  2.6474\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.8863  1.1691 -6.6658 -6.1863  8.0160\n",
       "   0.7758 -3.3039 -6.2509  0.1359 -7.6054\n",
       "  -2.4026  3.2416  7.7674  6.1687  0.4846\n",
       "  -2.4082  4.4304 -6.2612  2.5691 -5.0249\n",
       "  -0.6511  1.1432  0.8793  2.7022 -7.8806\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.2982  1.3991 -7.7035  6.8418  6.1747\n",
       "  -6.3455 -7.1565  5.3719  3.6577 -3.3860\n",
       "   0.3047  2.3262 -2.9309  5.0985  6.5932\n",
       "   6.3811  0.9574  0.2598  3.4968 -2.0846\n",
       "  -4.3769  0.8718  6.7591  2.4699  2.3607\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.4047  5.4964  5.3490  1.6498  2.9362\n",
       "  -7.2214  5.1219 -0.3187  2.3599  0.7260\n",
       "   0.8294 -7.2119 -2.6680 -6.9304  4.4011\n",
       "   2.9905 -5.3927 -5.1148  6.4237  0.2881\n",
       "   3.8662 -7.7914  6.7697  4.4761  0.2623\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.2070  1.4792  5.0395 -4.3123  4.6412\n",
       "   3.0348  0.7183 -2.1952  7.6926  4.7821\n",
       "  -3.1494 -5.4345 -6.2870 -3.2197  0.5525\n",
       "   2.0426  2.8422 -0.4890 -1.2276 -2.1386\n",
       "   6.3666 -4.8507 -2.8497  1.1452  6.0303\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.7321 -2.4577 -3.7696  3.5589  7.0323\n",
       "   5.3855  0.9742  2.7354 -5.4321 -6.9277\n",
       "   3.8931  6.6591 -3.5099 -0.3106  3.0685\n",
       "  -0.3254 -6.9363 -2.9063  5.4645 -6.5920\n",
       "   3.8555 -3.7378 -2.9353  3.6358 -0.5501\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.7204  1.3395 -3.7866  1.7736 -6.8423\n",
       "   1.8130  6.9361 -4.5842  0.3419 -2.6388\n",
       "  -3.4865  0.2658  5.1699 -6.0307 -4.1254\n",
       "  -0.6316  6.9765  3.4516  0.6518 -7.6746\n",
       "  -4.8295 -8.0794 -4.0758 -2.0780 -4.6060\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.2066  4.6947  6.8020 -7.3927 -3.0441\n",
       "  -2.9591  1.5106 -0.0050  0.3605  4.4186\n",
       "  -3.2578  0.1712  0.4282 -5.9800  5.4954\n",
       "  -4.7657 -3.5643  7.3281  3.5148  1.0849\n",
       "   6.5202  5.5291 -6.3269 -7.3798  7.9341\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.2900  1.2502 -2.6412  7.2901  0.0447\n",
       "  -7.4547 -6.8432  2.3795  7.9411  7.7526\n",
       "  -6.0853 -0.2466 -6.7620  4.6038 -2.5961\n",
       "  -2.7715  7.7296  2.2957  1.8226 -5.1845\n",
       "   2.1027 -5.8661 -5.9878 -3.0184 -0.8745\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.3636  7.1074  2.4778  2.0199  6.3396\n",
       "   3.1426 -7.3272  4.5191 -0.6836  6.4531\n",
       "  -1.7741  1.6192 -4.0413  2.6387 -1.4509\n",
       "  -5.0888 -7.9730 -5.4862 -1.9538 -2.3530\n",
       "  -3.9022 -0.4827 -5.8172 -5.4987  8.1317\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.9401 -4.6145 -6.7339  4.7447 -7.6786\n",
       "  -6.2387  2.2074  1.3397 -5.7587 -6.2743\n",
       "  -3.9140 -7.1012  3.3478  5.6370  5.0383\n",
       "   7.6805  3.1953  1.2133  6.7920  7.5333\n",
       "   6.6989  1.2811 -2.0816 -4.0340  0.3645\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.7267 -5.2882  5.5576  1.5774  7.5756\n",
       "  -1.7325 -0.4207  7.5684 -3.7405  2.8989\n",
       "   5.6785  2.4044 -8.1520  1.2784 -0.5231\n",
       "  -4.9858 -1.3472 -0.1298  1.7346 -7.0249\n",
       "  -6.4492  4.7321  6.3163  4.7207 -3.3720\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.3651  3.9455  8.0350  4.1445 -4.6374\n",
       "  -0.1168 -4.8892  1.7180  4.9201 -2.5566\n",
       "  -4.5428  6.1625  0.3531  8.1089  6.3079\n",
       "  -0.9686 -7.6347 -0.8675 -6.0744  2.7769\n",
       "   7.5697 -0.9456  5.1491  2.3133 -4.4634\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.0509  2.6152  6.4945 -1.6241 -6.4771\n",
       "   5.4697 -6.4557 -3.4109  7.6613  6.6214\n",
       "   6.8453  7.5821 -5.9442 -7.4083  3.0597\n",
       "  -3.8583 -3.1345  0.3166  4.0459 -6.0033\n",
       "   7.1274  3.8959 -2.3671  5.2451  3.1574\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.4698 -7.8090  3.2092 -4.0928 -6.3055\n",
       "  -2.2679 -5.5248  3.7415  3.9516 -3.4444\n",
       "   6.8274 -3.1510  5.1862  7.3195  3.7683\n",
       "   4.9829 -1.8062 -3.4795  3.6050  2.5771\n",
       "   0.9676  4.2465 -7.5530 -2.0600 -0.6709\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.3614 -1.8344  0.9276  7.8329  4.7127\n",
       "   7.1561  6.3573  5.8252  6.4754  4.5796\n",
       "  -7.9254  1.3333  4.5411  2.5702  5.2898\n",
       "   7.2193  5.5003  2.9368 -5.9275  7.7703\n",
       "   6.6343 -0.7086  0.4627 -7.7117  6.8824\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.7543  5.8502 -1.0973  8.0980  3.6753\n",
       "   2.9076  1.6516  2.5544  7.5465 -1.0341\n",
       "  -2.7167  2.5408 -1.1205  7.8680 -0.5232\n",
       "  -5.1279 -5.0872 -4.8088 -6.2405 -7.3469\n",
       "   3.4255  7.3045  1.2926 -2.3653  0.5009\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -8.1395  2.0861  7.7465 -6.2114  2.2696\n",
       "   2.6911  5.8310  4.9650  4.8384  1.1833\n",
       "   4.7658 -4.9407  3.9456 -7.4972 -3.4651\n",
       "  -1.5828  5.3898  7.7468  2.4815  2.4820\n",
       "  -2.3827  6.0516  7.2214  2.3155 -2.4847\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.5478  5.9580  4.5472  3.2182 -4.8756\n",
       "   1.8737  5.6221  1.2529  7.1082 -2.6086\n",
       "   2.7295 -7.0618  3.3115 -1.4414 -4.4496\n",
       "  -3.4461  1.8784  6.6417  5.0386  2.7911\n",
       "  -1.9418 -6.1846 -3.0892  4.0977  3.2747\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.8355  6.3988  6.3658  1.0804 -0.1664\n",
       "  -5.4253  6.7343  7.3323  2.2841  3.5418\n",
       "  -6.7229  0.9399  5.2182 -3.9657  4.5294\n",
       "  -5.9006  5.1819  4.7711 -5.8688  7.9621\n",
       "  -3.8588 -1.8572 -3.7068  2.3110 -2.2553\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.2035  5.1986  0.7448 -7.1084 -2.9410\n",
       "   1.9664  0.7929  0.2902  2.1644 -5.4328\n",
       "  -1.3370  2.1730 -3.5550  1.3274 -2.2098\n",
       "  -1.0334 -4.8397 -1.7725  3.8839 -6.1125\n",
       "   7.7705 -1.8811  2.5039  7.3691  6.1409\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.7007 -5.9919 -4.9957  6.2162  6.9435\n",
       "  -1.5671  5.3808  0.6926  6.4859 -6.0856\n",
       "   2.9535  3.5382 -4.8283 -6.1725  3.8185\n",
       "   2.7074  4.8010 -6.8778  2.1038 -1.5799\n",
       "   1.6517  0.3351 -7.3576 -0.1092  4.2208\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.5683  2.7981  3.9201  0.8888  5.1379\n",
       "  -0.4484  8.0858 -1.6290 -3.2107 -3.1558\n",
       "  -0.0351 -0.8203 -6.8579  0.3434  4.8089\n",
       "  -0.0096 -3.0999 -5.9079 -4.3931  3.2020\n",
       "  -5.3637 -5.6435 -8.1320 -0.0513  6.9147\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.2505 -0.1432  3.0228  0.2094  4.5999\n",
       "   6.3340 -0.4180  1.2550  3.7710 -5.0001\n",
       "  -1.5891  8.0215 -7.6897 -5.2293  1.9524\n",
       "   0.8292  5.8794  0.2079 -2.4933  7.5806\n",
       "   1.2331 -6.1210 -2.1615 -0.8401 -4.4742\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.9394  6.8732 -3.7286  4.4324  0.6632\n",
       "  -3.5538  0.7718  7.2449 -5.9807  4.7032\n",
       "  -1.9172  3.9374  1.4556 -5.5415  3.6610\n",
       "   5.8636 -0.4229  0.8394  4.6784  5.9412\n",
       "  -7.8089  6.7685 -1.8262  1.4411 -1.5255\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -2.5639\n",
       "  -2.4610\n",
       "   2.6434\n",
       "  -7.4345\n",
       "   1.8935\n",
       "  -3.1826\n",
       "  -3.9447\n",
       "  -3.3667\n",
       "  -6.7629\n",
       "  -1.5587\n",
       "   1.2181\n",
       "   4.1544\n",
       "  -1.0019\n",
       "   0.4286\n",
       "  -5.2088\n",
       "  -2.1121\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  2.7112  4.6867  4.5179  ...   2.4553  0.4046 -1.1999\n",
       " -0.7499 -3.9737 -2.2977  ...  -2.0654 -1.4012  3.7495\n",
       "  2.8011  1.0561  1.4660  ...  -1.7103 -3.8380 -4.7830\n",
       "           ...             ⋱             ...          \n",
       "  2.0188  0.8482 -0.3210  ...   3.8988  4.2462 -3.4412\n",
       "  3.9551  1.2814  3.7793  ...  -3.3284 -0.9740  4.3359\n",
       " -2.9365  2.8405  1.1786  ...   4.4523 -3.2977 -4.8757\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -0.5267\n",
       "  -0.1740\n",
       "  -4.2648\n",
       "   4.3799\n",
       "  -3.3312\n",
       "   1.3615\n",
       "  -0.6669\n",
       "  -0.9058\n",
       "   4.7946\n",
       "  -2.8599\n",
       "   4.4247\n",
       "  -3.5125\n",
       "  -0.4075\n",
       "  -1.0146\n",
       "   0.1030\n",
       "   1.6864\n",
       "   2.8981\n",
       "   3.3651\n",
       "   2.6884\n",
       "   2.9590\n",
       "   2.4149\n",
       "  -1.5095\n",
       "  -0.2183\n",
       "  -1.2500\n",
       "   1.2305\n",
       "   3.2360\n",
       "  -3.8394\n",
       "  -1.1760\n",
       "   2.4681\n",
       "  -4.0848\n",
       "  -3.1664\n",
       "  -2.9402\n",
       "   3.8460\n",
       "   3.0833\n",
       "   4.9173\n",
       "   2.7999\n",
       "   0.6196\n",
       "  -4.4631\n",
       "   4.4135\n",
       "  -4.2345\n",
       "   2.0375\n",
       "   2.6947\n",
       "  -2.4347\n",
       "   0.4212\n",
       "  -1.2132\n",
       "  -1.9376\n",
       "  -4.8434\n",
       "  -1.2264\n",
       "   2.1396\n",
       "   3.2642\n",
       "  -4.6997\n",
       "   3.4771\n",
       "   1.6652\n",
       "   3.7950\n",
       "  -2.6656\n",
       "  -4.1172\n",
       "   4.4997\n",
       "   1.9365\n",
       "  -2.5943\n",
       "   1.1568\n",
       "   0.3847\n",
       "  -0.3902\n",
       "  -0.7267\n",
       "  -4.2732\n",
       "  -4.1396\n",
       "  -0.2267\n",
       "   4.5048\n",
       "  -0.0057\n",
       "  -3.9627\n",
       "  -4.4582\n",
       "  -3.5183\n",
       "  -0.8273\n",
       "   1.6171\n",
       "   4.0460\n",
       "   3.1125\n",
       "  -3.9981\n",
       "   0.8115\n",
       "   2.0645\n",
       "   1.2681\n",
       "   2.5143\n",
       "  -4.3306\n",
       "  -1.1471\n",
       "   1.0318\n",
       "   0.7227\n",
       "  -1.9722\n",
       "  -3.2163\n",
       "  -3.9263\n",
       "   3.0511\n",
       "   4.3589\n",
       "   0.7863\n",
       "   0.9461\n",
       "   3.8216\n",
       "   1.8041\n",
       "  -0.5032\n",
       "  -3.2847\n",
       "  -2.9388\n",
       "  -3.2182\n",
       "  -4.2191\n",
       "  -2.4476\n",
       "  -1.1927\n",
       "  -3.7417\n",
       "  -0.2450\n",
       "  -3.9855\n",
       "  -2.4860\n",
       "   3.9301\n",
       "   1.5866\n",
       "   2.2707\n",
       "  -0.0208\n",
       "  -2.9234\n",
       "  -3.6716\n",
       "  -2.6394\n",
       "   2.7471\n",
       "   1.4759\n",
       "  -4.7380\n",
       "   0.2074\n",
       "  -4.4696\n",
       "   0.6544\n",
       "  -1.1205\n",
       "   4.5305\n",
       "  -1.5645\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " -1.4120e-02 -6.9320e-02 -3.9490e-02  ...  -7.7377e-02  3.2371e-02 -3.7138e-02\n",
       " -2.9757e-03 -7.9362e-03 -6.6291e-02  ...   8.5736e-02  2.8947e-02  4.1389e-02\n",
       "  2.0999e-02 -7.6849e-02  1.7946e-02  ...  -2.3564e-02 -7.0959e-02 -4.1742e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.8684e-02  8.0845e-03 -1.8584e-02  ...   8.2229e-02 -6.3310e-02  4.9760e-02\n",
       "  8.8412e-02 -5.5180e-02 -6.7649e-02  ...   3.6468e-02  4.7583e-02  7.4332e-02\n",
       " -7.6773e-02 -5.8721e-02 -5.5287e-02  ...  -8.7262e-02 -5.2954e-03 -4.6429e-02\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -8.2548\n",
       "   5.4688\n",
       "  -3.9522\n",
       "   2.6004\n",
       "  -0.2725\n",
       "  -4.4285\n",
       "  -1.2986\n",
       "   3.5304\n",
       "  -9.0869\n",
       "  -6.8797\n",
       "   7.5740\n",
       "  -4.5632\n",
       "  -5.7486\n",
       "  -1.3137\n",
       "  -3.8320\n",
       "   6.1531\n",
       "   4.3646\n",
       "  -5.9210\n",
       "  -8.0335\n",
       "  -7.5016\n",
       "  -7.8999\n",
       "  -7.6893\n",
       "   5.9118\n",
       "  -0.7579\n",
       "  -7.4443\n",
       "   3.3110\n",
       "  -7.2173\n",
       "   1.1340\n",
       "   5.5108\n",
       "   0.7010\n",
       "   1.7169\n",
       "  -7.4259\n",
       "  -3.7433\n",
       "   0.4025\n",
       "   7.6561\n",
       "  -1.3098\n",
       "   8.6718\n",
       "   6.6216\n",
       "   8.1663\n",
       "  -8.0135\n",
       "   2.9490\n",
       "  -5.7680\n",
       "  -7.9576\n",
       "  -1.7251\n",
       "   2.4572\n",
       "   8.3777\n",
       "   0.9942\n",
       "  -8.8965\n",
       "   4.7055\n",
       "   5.3232\n",
       "   3.4365\n",
       "  -4.8253\n",
       "   9.0884\n",
       "   2.8329\n",
       "  -5.3949\n",
       "  -0.8772\n",
       "  -1.2854\n",
       "  -8.0965\n",
       "  -4.1884\n",
       "   9.1287\n",
       "   1.9980\n",
       "   3.6051\n",
       "   6.6753\n",
       "   0.1182\n",
       "  -4.5713\n",
       "   2.0426\n",
       "  -2.3549\n",
       "   8.5697\n",
       "   8.0936\n",
       "  -2.5537\n",
       "  -7.5849\n",
       "   0.3024\n",
       "  -0.2180\n",
       "   5.8432\n",
       "  -6.0725\n",
       "  -3.4680\n",
       "   3.1432\n",
       "  -5.3847\n",
       "  -8.0226\n",
       "  -4.6466\n",
       "  -8.3522\n",
       "  -1.2175\n",
       "  -7.0401\n",
       "   1.0294\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.0023 -0.0524  0.0221  0.0357  0.1076 -0.0495  0.0832 -0.0459  0.0893  0.0059\n",
       " -0.0012 -0.0781  0.0263  0.0832 -0.0743  0.0661  0.0288 -0.0837  0.0789 -0.0020\n",
       "  0.0585  0.0626 -0.0979  0.0300  0.0075  0.0627 -0.0897 -0.0645  0.0855 -0.0575\n",
       "  0.0862  0.0413  0.1015  0.0630 -0.0743 -0.1045  0.0573 -0.0790 -0.0597  0.0433\n",
       "  0.0517  0.0659  0.0315 -0.0484 -0.0952  0.0778  0.0413  0.0528  0.1050  0.0709\n",
       " -0.0997  0.0107  0.0630 -0.0259  0.0998 -0.0036 -0.0424  0.0040 -0.1077 -0.0548\n",
       " -0.0774 -0.0116  0.0470 -0.0871 -0.0292  0.1026 -0.0087  0.0855  0.0938 -0.0744\n",
       " -0.0771 -0.0337  0.0590 -0.1058 -0.0098 -0.0639  0.0118  0.0058 -0.0002 -0.0098\n",
       " -0.1054 -0.0980  0.0588 -0.0692 -0.0154 -0.0564 -0.0764  0.0473 -0.0986  0.0729\n",
       "  0.0790  0.0440 -0.0084 -0.0634  0.0113  0.0861 -0.0074  0.0956 -0.0182 -0.0541\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.0466  0.0042  0.0702  0.0092  0.0529 -0.0825 -0.0159 -0.0847 -0.0211 -0.0840\n",
       "  0.1057  0.0875  0.0496  0.0612 -0.1050 -0.0757 -0.0889  0.0506  0.0090  0.0597\n",
       "  0.0236  0.0744  0.0041 -0.0366 -0.0034 -0.0701 -0.0463 -0.1082 -0.1067  0.0321\n",
       " -0.0423  0.0781  0.0525  0.0454  0.0238 -0.0192  0.0433 -0.0514 -0.0911 -0.0022\n",
       " -0.0962  0.0567 -0.0164  0.0823  0.0794  0.0512 -0.0502 -0.0422 -0.0066 -0.0446\n",
       " -0.0616 -0.0884 -0.0191 -0.0752 -0.0079 -0.0283 -0.0208  0.0140  0.0337  0.0041\n",
       "  0.0812 -0.0690 -0.0885 -0.0962 -0.0837 -0.0496 -0.0161  0.0487 -0.0305  0.0149\n",
       " -0.0139 -0.0113 -0.0615 -0.0256 -0.0580 -0.0867 -0.0784 -0.0571  0.0805  0.0656\n",
       " -0.0131  0.0121  0.0166 -0.0784  0.1018  0.0440 -0.0424 -0.0302 -0.0024  0.0579\n",
       " -0.0093 -0.0089 -0.0220 -0.0963  0.0542 -0.0132  0.0586  0.0483  0.0735 -0.1005\n",
       " \n",
       " Columns 20 to 29 \n",
       " -0.0709  0.0189  0.0722  0.0158  0.0378  0.0721  0.0046 -0.0727 -0.0735  0.0950\n",
       " -0.0405  0.0774  0.0715  0.1004 -0.0964  0.1031 -0.0801  0.0416 -0.0871  0.0159\n",
       "  0.0313  0.0452 -0.0011  0.0952 -0.0412 -0.0800 -0.0517  0.0170 -0.0070 -0.0579\n",
       "  0.0889 -0.0517 -0.0253  0.0218  0.0297  0.0491  0.0875  0.0558  0.1059 -0.1073\n",
       "  0.0866  0.0655  0.0646  0.0834  0.0517  0.0280  0.0460  0.0056 -0.0318 -0.0883\n",
       " -0.0483 -0.0413 -0.0013 -0.0272 -0.0071 -0.0363  0.0544  0.0225 -0.0628 -0.0830\n",
       " -0.0393 -0.0891  0.0005 -0.0353 -0.1081 -0.0188 -0.1035  0.0121 -0.0089 -0.0260\n",
       "  0.0548  0.1085  0.0139 -0.1022 -0.0857 -0.0871  0.0287 -0.0460  0.0312  0.0915\n",
       " -0.0395  0.0596  0.0189 -0.0390 -0.0022 -0.0844 -0.0908  0.0493 -0.0751 -0.0568\n",
       "  0.0538 -0.1023  0.0713  0.0926 -0.0209 -0.0695 -0.0174  0.0314  0.0349  0.0905\n",
       " \n",
       " Columns 30 to 39 \n",
       "  0.0157  0.0401  0.0929 -0.0644 -0.0011  0.0476 -0.0149  0.0152  0.0453  0.0750\n",
       "  0.0789  0.0629  0.0482  0.0955 -0.0798 -0.0657 -0.0263  0.1018  0.0436  0.0716\n",
       "  0.0325  0.0180  0.0175  0.0007  0.0574 -0.0462  0.0339  0.0035 -0.0907 -0.0273\n",
       " -0.0137  0.0097  0.0808 -0.0878  0.1083 -0.0081 -0.0125 -0.0582 -0.0269 -0.1014\n",
       "  0.1050  0.0025 -0.0929 -0.0265 -0.0181  0.0813 -0.0755 -0.0187  0.0961  0.0434\n",
       "  0.0005 -0.0951 -0.0612  0.1080 -0.1068  0.0037  0.0725  0.0471  0.0418  0.0331\n",
       "  0.0875  0.0168 -0.1058 -0.1003  0.0263 -0.0291 -0.0270  0.0050  0.0353 -0.0676\n",
       "  0.0137 -0.0023 -0.0677 -0.0859  0.0929  0.0242 -0.0699  0.0202  0.0462 -0.0227\n",
       " -0.0111  0.0818 -0.0086  0.0653 -0.0570  0.0760  0.0767  0.1081  0.0832 -0.0223\n",
       " -0.0876 -0.0424  0.0992  0.0274 -0.0169  0.1083  0.0489 -0.0041 -0.0152 -0.0388\n",
       " \n",
       " Columns 40 to 49 \n",
       " -0.0079  0.0718  0.0144  0.0641 -0.0686  0.0276  0.0788  0.0766 -0.0159  0.0449\n",
       "  0.0043 -0.0494 -0.0773  0.0015 -0.0056 -0.0352  0.0028 -0.0717  0.0875  0.0101\n",
       "  0.0681  0.0816  0.0569 -0.0862  0.1062 -0.0492  0.0793  0.0409  0.0405 -0.0030\n",
       " -0.0783 -0.0960 -0.0880 -0.0641 -0.0698 -0.0893 -0.1057  0.0987 -0.0264  0.0827\n",
       "  0.0719 -0.0299  0.0018  0.0947  0.0423  0.0310  0.0133 -0.0810 -0.0112  0.0275\n",
       "  0.0140  0.0857 -0.0825 -0.0065 -0.0573  0.0329 -0.0897  0.1003 -0.0057  0.0020\n",
       " -0.0326 -0.0772 -0.0081  0.0333  0.0990  0.0717  0.0383  0.0377  0.0837  0.0320\n",
       "  0.0916  0.0154 -0.0425 -0.0645 -0.0015 -0.0787  0.0674  0.0351 -0.0063 -0.0892\n",
       " -0.0530 -0.0704 -0.0160  0.0235 -0.0404  0.0494  0.0091  0.0395  0.0147  0.0487\n",
       " -0.0401  0.0383  0.0054 -0.1012 -0.0878 -0.0149 -0.0560 -0.0344 -0.0153 -0.0828\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.0431  0.0689 -0.0208  0.0347  0.0794  0.0525  0.1027  0.0551 -0.0814  0.0474\n",
       " -0.1069 -0.0284 -0.0895  0.0703 -0.0851 -0.0315  0.0334  0.0482  0.0091 -0.0936\n",
       "  0.0112 -0.0253  0.0905  0.0880 -0.0086  0.0584 -0.0377  0.0899  0.0429  0.0928\n",
       "  0.0035  0.0794 -0.0769 -0.0908  0.0480 -0.1082 -0.0067 -0.0427 -0.0953 -0.0231\n",
       "  0.0668  0.0385 -0.0382  0.0433  0.0750 -0.0549  0.0051  0.0973 -0.0788  0.0765\n",
       "  0.0323  0.0513 -0.1017 -0.0618  0.0725  0.0041 -0.0853  0.0639 -0.0527  0.0907\n",
       " -0.0059  0.0816  0.0442 -0.1012 -0.0265  0.0441  0.0530 -0.0946 -0.0682  0.0273\n",
       " -0.0074  0.0361  0.0225 -0.0059 -0.0600  0.0874 -0.1024  0.0825  0.0894  0.0843\n",
       "  0.0283  0.0390  0.0760  0.0343 -0.0419  0.1089 -0.0686  0.1069 -0.0842  0.1053\n",
       " -0.0641  0.0929  0.1038  0.1036  0.0135  0.0187  0.0389 -0.0096 -0.0160  0.0389\n",
       " \n",
       " Columns 60 to 69 \n",
       "  0.0093  0.0918  0.0066  0.0204  0.1043 -0.0128  0.0925 -0.0381 -0.0370  0.0503\n",
       " -0.0857  0.0824  0.0279 -0.0876  0.0869  0.0534 -0.0719 -0.1028 -0.0192 -0.0940\n",
       " -0.0130  0.0852  0.0854 -0.0771  0.0867  0.0915 -0.0566 -0.0547 -0.0058  0.0182\n",
       "  0.0416  0.0573 -0.0898 -0.0641  0.0177  0.0168 -0.0028 -0.0008  0.0250  0.0236\n",
       "  0.0112  0.0472 -0.0057 -0.0463 -0.1008 -0.0425  0.0056  0.1008  0.0928  0.0861\n",
       "  0.0590 -0.1027 -0.0428  0.0536 -0.1082  0.0145 -0.0039 -0.0706 -0.0154 -0.0504\n",
       " -0.0332  0.0877  0.0867 -0.0209  0.0680 -0.1060 -0.0515 -0.0495 -0.0624 -0.0319\n",
       " -0.0021 -0.0098 -0.0782  0.0302 -0.0839 -0.0845 -0.0020 -0.1018 -0.1077  0.0749\n",
       "  0.0045  0.0925 -0.1066  0.0245  0.0528  0.0365  0.0828  0.0796 -0.0131  0.0677\n",
       "  0.0625  0.0456  0.0378 -0.0753 -0.0505  0.0712  0.0541  0.0202 -0.0724  0.1011\n",
       " \n",
       " Columns 70 to 79 \n",
       " -0.0007 -0.0222 -0.0384  0.0462  0.0050  0.0953  0.0361 -0.1001  0.0116  0.0508\n",
       "  0.0756 -0.0059  0.0499 -0.0573 -0.0311 -0.0385 -0.0397 -0.1028 -0.0734 -0.1059\n",
       " -0.1012  0.0276 -0.0384  0.0610 -0.0554 -0.0038 -0.0654 -0.0662  0.0660 -0.0331\n",
       " -0.0217  0.0795 -0.0632  0.0586  0.0678 -0.1033 -0.0617 -0.0580  0.0106 -0.0826\n",
       "  0.0310  0.0049  0.0328  0.0161 -0.0135 -0.0649  0.0152  0.0394 -0.0086  0.0899\n",
       " -0.0579  0.0197  0.0859  0.0950  0.0645  0.0999 -0.1045  0.0547 -0.0864 -0.0792\n",
       "  0.0764  0.0875  0.0341  0.0701 -0.0954 -0.0479 -0.0789  0.0885 -0.0536 -0.0549\n",
       " -0.0430  0.1047  0.0979  0.0009 -0.0298 -0.0633  0.0820 -0.0672 -0.0373  0.0220\n",
       "  0.0685 -0.0330 -0.0202 -0.0051 -0.0742  0.0953  0.0660 -0.0077  0.0893  0.0497\n",
       "  0.0884  0.0759  0.0583 -0.0862  0.0955 -0.0899  0.0378  0.0480  0.0144  0.0927\n",
       " \n",
       " Columns 80 to 83 \n",
       " -0.0179 -0.1040 -0.0362 -0.0246\n",
       " -0.0730  0.0352 -0.0934 -0.0359\n",
       "  0.0582 -0.0933  0.0890 -0.0763\n",
       "  0.0367 -0.0277 -0.0421  0.0892\n",
       "  0.0593  0.0240  0.0195 -0.0256\n",
       "  0.0559 -0.0453 -0.0029 -0.0250\n",
       " -0.0084  0.0869 -0.0904 -0.0246\n",
       " -0.0285  0.0060  0.0374  0.0305\n",
       " -0.0769  0.0643  0.0262 -0.0698\n",
       " -0.0519 -0.0085 -0.0906  0.0941\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -8.8514\n",
       "  -0.7231\n",
       "   7.1664\n",
       "  -1.1780\n",
       "  -9.2142\n",
       "  -9.7048\n",
       "  -6.9753\n",
       "   2.5266\n",
       "  -4.6980\n",
       "   5.3292\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.0992  0.1677 -0.1258  0.0381  0.0935\n",
       " -0.1119  0.0292  0.0019  0.1882 -0.1174\n",
       "  0.0381  0.1954  0.0352 -0.0662 -0.0212\n",
       " -0.0932 -0.1167  0.1073 -0.0009  0.1536\n",
       " -0.1049  0.1667  0.0398 -0.0735 -0.1644\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "  0.1478 -0.0086  0.0004  0.0514  0.0919\n",
       "  0.1457 -0.0984  0.0095 -0.1063 -0.1642\n",
       " -0.1211 -0.0235 -0.1344  0.1966 -0.1802\n",
       " -0.1462  0.1145  0.1714 -0.1523 -0.1133\n",
       " -0.1520  0.1304 -0.0317 -0.1527  0.1538\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "  0.0733  0.1316  0.1687 -0.0617  0.1013\n",
       "  0.1343 -0.0202 -0.0492  0.1115  0.1382\n",
       " -0.1112 -0.1679  0.1365  0.1945  0.0409\n",
       "  0.1372 -0.1470  0.1027 -0.0408  0.0516\n",
       " -0.0901 -0.0411 -0.0677 -0.1372 -0.0567\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       "  0.1641  0.0936 -0.1168  0.0829  0.0724\n",
       "  0.1183  0.1898  0.1678 -0.0585 -0.1817\n",
       " -0.1199  0.1507  0.1504 -0.1702  0.0586\n",
       " -0.1399 -0.1842 -0.0353  0.0875 -0.1266\n",
       "  0.0528 -0.1486  0.1896  0.1766  0.1904\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       "  0.1848  0.0359  0.1397 -0.1356 -0.1437\n",
       "  0.0207  0.1274  0.0827 -0.1108  0.0419\n",
       "  0.1083 -0.0749 -0.1973  0.1260 -0.1922\n",
       "  0.1563  0.0226  0.1965  0.1543  0.0348\n",
       " -0.0128  0.1305  0.0338  0.1625  0.0935\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       "  0.1600  0.0999  0.1234  0.0052 -0.1074\n",
       " -0.0755  0.1480 -0.1497  0.1177 -0.1509\n",
       "  0.0845 -0.1669 -0.0591  0.1730  0.1089\n",
       "  0.0914  0.0534 -0.1195 -0.1644 -0.1105\n",
       " -0.0835  0.1830 -0.0167  0.1945 -0.0441\n",
       "[torch.FloatTensor of size 6x1x5x5]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0303 -0.0005  0.0960 -0.0786 -0.0568 -0.1317 -0.0535  0.0285 -0.0044  0.0536\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic forward and backward propagation\n",
    "input = Variable(torch.randn(1,1,32,32))\n",
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10), retain_variables = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary so far\n",
    "- Torch.Tensor is a multi-dimensional array\n",
    "- autograd.Variable - Tensor + History + backwards + gradient object\n",
    "- nn.Module - neural net encapsulation\n",
    "- autograd.function - implementation of forward and baackwrds prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 38.6609\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(input)\n",
    "target = Variable(torch.range(1,10))\n",
    "crit = nn.MSELoss()\n",
    "loss = crit(out, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "lr = 0.01\n",
    "for f in net.parameters():\n",
    "    optimizer.zero_grad()\n",
    "    out = net(input)\n",
    "    loss = crit(out, target)\n",
    "    loss.backward(retain_variables = True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
